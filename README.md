# actune
This is the code repo for our paper `ACTUNE: Uncertainty-Aware Active Self-Training for Active Fine-Tuning of Pretrained Language Models' (NAACL 2022).

We will release our camera ready paper and the code soon. Stay tuned!
