# actune
This is the code repo for our paper `ACTUNE: Uncertainty-Aware Active Self-Training for Active Fine-Tuning of Pretrained Language Models' (NAACL 2022).
